
# Fixed Streamlit App with Instant Word Download (no rerun required)
# - Keeps full Excel features and dashboards
# - Word generation now mirrors your working debug_test.py flow:
#   generate -> convert to bytes -> show st.download_button immediately

import streamlit as st
import pandas as pd
from io import BytesIO, StringIO
from datetime import datetime
import pytz
import traceback
import sys
import os

# ---------- Word generator availability check ----------
WORD_REPORT_AVAILABLE = False
WORD_IMPORT_ERROR = None
try:
    from docx import Document  # dependency sanity check
    # Import lazily inside the button as well, but try here to surface status
    from word_report_generator import test_word_generator
    ok, msg = test_word_generator()
    WORD_REPORT_AVAILABLE = ok
    if not ok:
        WORD_IMPORT_ERROR = msg
except Exception as e:
    WORD_IMPORT_ERROR = str(e)

# ---------- Page setup ----------
st.set_page_config(
    page_title="üè¢ Inspection Report Processor",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------- Styles ----------
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #4CAF50, #2196F3);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .main-header h1 { color: white; margin: 0; font-size: 2.6rem; font-weight: 800; }
    .main-header p { color: white; margin: .6rem 0 0 0; font-size: 1.1rem; opacity: .95; }

    .metric-card { background: #fff; padding: 1.3rem; border-radius: 14px; border: 1px solid #eee;
                   text-align:center; box-shadow: 0 2px 10px rgba(0,0,0,.05); }
    .metric-value { font-size: 2rem; font-weight: 800; color: #2E7D32; }
    .metric-label { color:#666; margin-top:.3rem; }

    .section-header { background: linear-gradient(135deg, #6c5ce7, #a29bfe);
                      color:#fff; padding:.8rem 1.2rem; border-radius:10px; text-align:center; margin: 1.2rem 0; }

    .readiness-card { padding:.9rem; border-radius:10px; margin:.5rem 0; font-weight:600; text-align:center; }
    .ready { background:#C8E6C9; }
    .minor { background:#FFF3C4; }
    .major { background:#FFCDD2; }
    .extensive { background:#F8BBD9; }

    .trade-item { background:#fff; border-left:5px solid #2196f3; padding:1rem; border-radius:10px; margin:.5rem 0;
                  box-shadow:0 1px 8px rgba(0,0,0,.06); }
    .success-message { background: linear-gradient(135deg,#d4edda,#c3e6cb); color:#155724; padding:1rem; border-radius:10px; }

    .error-card { background: linear-gradient(135deg, #ffebee, #ffcdd2); padding: .8rem; border-left: 4px solid #f44336; border-radius:8px; }
</style>
""", unsafe_allow_html=True)

# ---------- Header ----------
st.markdown("""
<div class="main-header">
  <h1>üè¢ Inspection Report Processor</h1>
  <p>Upload iAuditor CSV files ‚Üí Generate beautiful Excel & Word reports (with custom trade mapping)</p>
</div>
""", unsafe_allow_html=True)

# ---------- Utils ----------
def load_default_mapping():
    """Inline default trade mappings (quick start)."""
    master_mapping_csv = """Room,Component,Trade
Apartment Entry Door,Door Handle,Doors
Apartment Entry Door,Door Locks and Keys,Doors
Apartment Entry Door,Paint,Painting
Apartment Entry Door,Self Latching,Doors
Balcony,Balustrade,Carpentry & Joinery
Balcony,Drainage Point,Plumbing
Balcony,GPO (if applicable),Electrical
Balcony,Glass,Windows
Balcony,Glass Sliding Door,Windows
Balcony,Tiles,Flooring - Tiles
Bathroom,Bathtub (if applicable),Plumbing
Bathroom,Ceiling,Painting
Bathroom,Doors,Doors
Bathroom,Exhaust Fan,Electrical
Bathroom,GPO,Electrical
Bathroom,Light Fixtures,Electrical
Bathroom,Mirror,Carpentry & Joinery
Bathroom,Shower,Plumbing
Bathroom,Sink,Plumbing
Bathroom,Skirting,Carpentry & Joinery
Bathroom,Tiles,Flooring - Tiles
Bathroom,Toilet,Plumbing
Bathroom,Walls,Painting
Bedroom,Carpets,Flooring - Carpets
Bedroom,Ceiling,Painting
Bedroom,Doors,Doors
Bedroom,GPO,Electrical
Bedroom,Light Fixtures,Electrical
Bedroom,Skirting,Carpentry & Joinery
Bedroom,Walls,Painting
Bedroom,Wardrobe,Carpentry & Joinery
Bedroom,Windows,Windows
Kitchen Area,Cabinets,Carpentry & Joinery
Kitchen Area,Ceiling,Painting
Kitchen Area,Dishwasher,Plumbing
Kitchen Area,Flooring,Flooring - Timber
Kitchen Area,GPO,Electrical
Kitchen Area,Kitchen Sink,Plumbing
Kitchen Area,Light Fixtures,Electrical
Kitchen Area,Rangehood,Appliances
Kitchen Area,Stovetop and Oven,Appliances
Living Room,Ceiling,Painting
Living Room,Flooring,Flooring - Timber
Living Room,GPO,Electrical
Living Room,Light Fixtures,Electrical
Living Room,Walls,Painting
Living Room,Windows,Windows
Laundry Room,Doors,Doors
Laundry Room,GPO,Electrical
Laundry Room,Laundry Sink,Plumbing
Laundry Room,Light Fixtures,Electrical
Laundry Room,Tiles,Flooring - Tiles
Laundry Room,Walls,Painting"""
    return pd.read_csv(StringIO(master_mapping_csv))

def get_available_trades():
    return [
        "Doors","Electrical","Plumbing","Painting","Carpentry & Joinery",
        "Flooring - Tiles","Flooring - Carpets","Flooring - Timber","Windows","Appliances"
    ]

# Session state
if "trade_mapping" not in st.session_state:
    st.session_state.trade_mapping = None
if "mapping_edited" not in st.session_state:
    st.session_state.mapping_edited = False

# ---------- Data processing helpers (trimmed for brevity but consistent) ----------
def process_inspection_data(df, trade_mapping):
    # Unit
    if "Lot Details_Lot Number" in df.columns and df["Lot Details_Lot Number"].notna().any():
        df["Unit"] = df["Lot Details_Lot Number"].astype(str).str.strip()
    elif "Title Page_Lot number" in df.columns and df["Title Page_Lot number"].notna().any():
        df["Unit"] = df["Title Page_Lot number"].astype(str).str.strip()
    else:
        df["Unit"] = [f"Unit_{i}" for i in range(1, len(df)+1)]
    # UnitType
    if "Pre-Settlement Inspection_Unit Type" in df.columns:
        df["UnitType"] = df["Pre-Settlement Inspection_Unit Type"].fillna("Unknown")
    else:
        df["UnitType"] = "Unknown"

    # Inspection columns
    inspection_cols = [c for c in df.columns if c.startswith("Pre-Settlement Inspection_") and not c.endswith("_notes")]
    if not inspection_cols:
        inspection_cols = [c for c in df.columns if any(k in c.lower() for k in ["inspection","defect","item","status","check"])]

    long_df = df.melt(
        id_vars=["Unit","UnitType"],
        value_vars=inspection_cols,
        var_name="InspectionItem",
        value_name="Status"
    )

    parts = long_df["InspectionItem"].str.split("_", n=2, expand=True)
    if len(parts.columns) >= 3:
        long_df["Room"] = parts[1]
        comp = parts[2].str.replace(r"\.\d+$","", regex=True)
        long_df["Component"] = comp.apply(lambda x: x.split("_")[-1] if isinstance(x, str) else x)
    else:
        long_df["Room"] = "General"
        long_df["Component"] = long_df["InspectionItem"].str.replace("Pre-Settlement Inspection_","")

    # Clean metadata rows
    long_df = long_df[~long_df["Room"].isin(["Unit Type","Building Type","Townhouse Type","Apartment Type"])]
    long_df = long_df[~long_df["Component"].isin(["Room Type"])]

    def classify_status(v):
        if pd.isna(v) or str(v).strip()=="":
            return "Blank"
        s = str(v).strip().lower()
        if s in ["‚úì","‚úî","ok","pass","passed","good","satisfactory"]:
            return "OK"
        elif s in ["‚úó","‚úò","x","fail","failed","not ok","defect","issue"]:
            return "Not OK"
        else:
            return "Not OK"

    long_df["StatusClass"] = long_df["Status"].apply(classify_status)

    merged = long_df.merge(trade_mapping, on=["Room","Component"], how="left")
    merged["Trade"] = merged["Trade"].fillna("Unknown Trade")

    final_df = merged[["Unit","UnitType","Room","Component","StatusClass","Trade"]]

    return final_df, df

def generate_component_details_summary(defects_only):
    if len(defects_only)==0:
        return pd.DataFrame(columns=["Trade","Room","Component","Units with Defects"])
    comp = defects_only.groupby(["Trade","Room","Component"])["Unit"].apply(
        lambda s: ", ".join(sorted(s.astype(str).unique()))
    ).reset_index().rename(columns={"Unit":"Units with Defects"})
    comp["Unit_Count"] = comp["Units with Defects"].apply(lambda x: len(x.split(", ")) if x else 0)
    comp = comp.sort_values(["Trade","Unit_Count"], ascending=[True, False])
    return comp[["Trade","Room","Component","Units with Defects"]]

def calculate_metrics(final_df, df):
    defects_only = final_df[final_df["StatusClass"]=="Not OK"]
    sample = df["auditName"].dropna().iloc[0] if "auditName" in df.columns and df["auditName"].dropna().any() else ""
    if sample:
        parts = str(sample).split("/")
        building_name = parts[2].strip() if len(parts)>=3 else "Unknown Building"
        inspection_date = parts[0].strip() if len(parts)>=1 else datetime.now().strftime("%Y-%m-%d")
    else:
        building_name = "Unknown Building"
        inspection_date = datetime.now().strftime("%Y-%m-%d")

    location = df.get("Title Page_Site conducted_Location", pd.Series(dtype=str)).dropna()
    area = df.get("Title Page_Site conducted_Area", pd.Series(dtype=str)).dropna()
    region = df.get("Title Page_Site conducted_Region", pd.Series(dtype=str)).dropna()
    address = ", ".join([s.astype(str).iloc[0].strip() for s in [location,area,region] if len(s)>0]) if any([len(location)>0,len(area)>0,len(region)>0]) else "Address Not Available"

    unit_types = ", ".join(sorted(final_df["UnitType"].dropna().astype(str).unique())) if len(final_df)>0 else "Unknown"
    total_units = final_df["Unit"].nunique()
    total_inspections = len(final_df)
    total_defects = len(defects_only)
    defect_rate = (total_defects/total_inspections*100) if total_inspections>0 else 0
    avg_defects_per_unit = (total_defects/total_units) if total_units>0 else 0

    dc = defects_only.groupby("Unit").size()
    ready_units = (dc<=2).sum()
    minor_work_units = ((dc>=3)&(dc<=7)).sum()
    major_work_units = ((dc>=8)&(dc<=15)).sum()
    extensive_work_units = (dc>15).sum()
    units_with_defects = set(dc.index)
    all_units = set(final_df["Unit"].dropna())
    ready_units += len(all_units-units_with_defects)

    denom = total_units if total_units>0 else 1
    ready_pct = ready_units/denom*100
    minor_pct = minor_work_units/denom*100
    major_pct = major_work_units/denom*100
    extensive_pct = extensive_work_units/denom*100

    summary_trade = defects_only.groupby("Trade").size().reset_index(name="DefectCount").sort_values("DefectCount", ascending=False)
    summary_unit = defects_only.groupby("Unit").size().reset_index(name="DefectCount").sort_values("DefectCount", ascending=False)
    summary_room = defects_only.groupby("Room").size().reset_index(name="DefectCount").sort_values("DefectCount", ascending=False)
    summary_unit_trade = defects_only.groupby(["Unit","Trade"]).size().reset_index(name="DefectCount")
    summary_room_comp = defects_only.groupby(["Room","Component"]).size().reset_index(name="DefectCount").sort_values("DefectCount", ascending=False)

    trade_specific_summary = pd.DataFrame()  # (optional detailed table omitted to keep code lighter)
    component_details_summary = generate_component_details_summary(defects_only)

    return {
        "building_name": building_name,
        "inspection_date": inspection_date,
        "address": address,
        "unit_types_str": unit_types,
        "total_units": total_units,
        "total_inspections": total_inspections,
        "total_defects": total_defects,
        "defect_rate": defect_rate,
        "avg_defects_per_unit": avg_defects_per_unit,
        "ready_units": ready_units,
        "minor_work_units": minor_work_units,
        "major_work_units": major_work_units,
        "extensive_work_units": extensive_work_units,
        "ready_pct": ready_pct,
        "minor_pct": minor_pct,
        "major_pct": major_pct,
        "extensive_pct": extensive_pct,
        "summary_trade": summary_trade,
        "summary_unit": summary_unit,
        "summary_room": summary_room,
        "summary_unit_trade": summary_unit_trade,
        "summary_room_comp": summary_room_comp,
        "defects_only": defects_only,
        "trade_specific_summary": trade_specific_summary,
        "component_details_summary": component_details_summary
    }

def generate_excel(final_df, metrics):
    """Lightweight Excel to keep focus on Word fix; still produces data sheets."""
    try:
        import xlsxwriter  # ensure engine available
    except Exception:
        st.warning("xlsxwriter not installed; Excel download will be disabled.")
        return None

    out = BytesIO()
    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        final_df.to_excel(writer, sheet_name="All Inspections", index=False)
        if len(metrics["defects_only"])>0:
            metrics["defects_only"].to_excel(writer, sheet_name="Defects Only", index=False)
        if len(metrics["summary_trade"])>0:
            metrics["summary_trade"].to_excel(writer, sheet_name="By Trade", index=False)
        if len(metrics["summary_unit"])>0:
            metrics["summary_unit"].to_excel(writer, sheet_name="By Unit", index=False)
        if len(metrics["summary_room"])>0:
            metrics["summary_room"].to_excel(writer, sheet_name="By Room", index=False)
        if len(metrics["component_details_summary"])>0:
            metrics["component_details_summary"].to_excel(writer, sheet_name="Component Details", index=False)
    out.seek(0)
    return out

# ---------- Tabs ----------
tab1, tab2, tab3 = st.tabs(["üì§ Upload & Process", "üó∫Ô∏è Manage Trade Mapping", "üìä Debug & Support"])

with tab2:
    st.markdown("## üó∫Ô∏è Trade Mapping")
    col1, col2 = st.columns([2,1])

    with col1:
        mapping_source = st.radio(
            "Choose your mapping source:",
            ["Load default mapping", "Upload custom mapping file", "Start with empty mapping"],
            help="How to initialize your trade mapping"
        )
    with col2:
        if st.button("üîÑ Reset to Default"):
            st.session_state.trade_mapping = load_default_mapping()
            st.session_state.mapping_edited = True
            st.success("Default mapping loaded.")

    if mapping_source == "Upload custom mapping file":
        up = st.file_uploader("Upload Trade Mapping CSV (Room, Component, Trade)", type=["csv"], key="mapping_up")
        if up is not None:
            try:
                m = pd.read_csv(up)
                if all(c in m.columns for c in ["Room","Component","Trade"]):
                    st.session_state.trade_mapping = m
                    st.session_state.mapping_edited = True
                    st.success(f"Loaded {len(m)} mappings.")
                else:
                    st.error("CSV must have columns: Room, Component, Trade")
            except Exception as e:
                st.error(f"Error reading mapping: {e}")
    elif mapping_source == "Load default mapping":
        if st.session_state.trade_mapping is None:
            st.session_state.trade_mapping = load_default_mapping()
            st.session_state.mapping_edited = True
    else:
        if st.session_state.trade_mapping is None or len(st.session_state.trade_mapping)>0:
            st.session_state.trade_mapping = pd.DataFrame(columns=["Room","Component","Trade"])
            st.session_state.mapping_edited = True

    if st.session_state.trade_mapping is not None:
        st.markdown("---")
        st.markdown("### ‚úèÔ∏è Edit Mapping")
        edited = st.data_editor(
            st.session_state.trade_mapping,
            use_container_width=True,
            num_rows="dynamic",
            column_config={
                "Room": st.column_config.TextColumn("Room", width="medium"),
                "Component": st.column_config.TextColumn("Component", width="large"),
                "Trade": st.column_config.SelectboxColumn("Trade", options=get_available_trades(), width="medium")
            },
            key="mapping_editor"
        )
        if not edited.equals(st.session_state.trade_mapping):
            st.session_state.trade_mapping = edited
            st.session_state.mapping_edited = True
            st.success("Mapping updated.")

with tab1:
    st.sidebar.title("‚öôÔ∏è Options")
    st.sidebar.markdown("---")
    if WORD_REPORT_AVAILABLE:
        st.sidebar.success("‚úÖ Word ready")
    else:
        st.sidebar.warning("‚ö†Ô∏è Word not ready")
        if WORD_IMPORT_ERROR:
            st.sidebar.code(f"Issue: {WORD_IMPORT_ERROR}")

    st.sidebar.subheader("üìß Notifications")
    st.sidebar.text_input("Email (optional)", key="notify_email")

    st.markdown("## üì§ Upload & Process Inspection Files")
    uploaded = st.file_uploader("Choose iAuditor CSV file", type=["csv"], key="data_up")

    if st.session_state.trade_mapping is not None and len(st.session_state.trade_mapping)>0:
        with st.expander("üîç Preview Current Trade Mapping"):
            st.dataframe(st.session_state.trade_mapping.head(10), use_container_width=True)

    if uploaded is not None and st.session_state.trade_mapping is not None and len(st.session_state.trade_mapping)>0:
        try:
            df = pd.read_csv(uploaded)
            st.success(f"‚úÖ Loaded {len(df)} rows from {uploaded.name}")

            final_df, processed_df = process_inspection_data(df, st.session_state.trade_mapping)
            metrics = calculate_metrics(final_df, processed_df)

            # --- Top metrics ---
            st.markdown('<div class="section-header">üìä Key Inspection Metrics</div>', unsafe_allow_html=True)
            c1,c2,c3,c4 = st.columns(4)
            c1.markdown(f'<div class="metric-card"><div class="metric-value">{metrics["total_units"]:,}</div><div class="metric-label">üè† Total Units</div></div>', unsafe_allow_html=True)
            c2.markdown(f'<div class="metric-card"><div class="metric-value">{metrics["total_defects"]:,}</div><div class="metric-label">‚ö†Ô∏è Total Defects</div></div>', unsafe_allow_html=True)
            c3.markdown(f'<div class="metric-card"><div class="metric-value">{metrics["defect_rate"]:.1f}%</div><div class="metric-label">üìä Defect Rate</div></div>', unsafe_allow_html=True)
            c4.markdown(f'<div class="metric-card"><div class="metric-value">{metrics["avg_defects_per_unit"]:.1f}</div><div class="metric-label">üìà Avg per Unit</div></div>', unsafe_allow_html=True)

            # --- Settlement readiness ---
            st.markdown('<div class="section-header">üè† Settlement Readiness</div>', unsafe_allow_html=True)
            l,r = st.columns(2)
            l.markdown(f'<div class="readiness-card ready">‚úÖ Ready (0-2 defects): {metrics["ready_units"]} units ({metrics["ready_pct"]:.1f}%)</div>', unsafe_allow_html=True)
            l.markdown(f'<div class="readiness-card minor">‚ö†Ô∏è Minor (3-7): {metrics["minor_work_units"]} units ({metrics["minor_pct"]:.1f}%)</div>', unsafe_allow_html=True)
            r.markdown(f'<div class="readiness-card major">üîß Major (8-15): {metrics["major_work_units"]} units ({metrics["major_pct"]:.1f}%)</div>', unsafe_allow_html=True)
            r.markdown(f'<div class="readiness-card extensive">üöß Extensive (15+): {metrics["extensive_work_units"]} units ({metrics["extensive_pct"]:.1f}%)</div>', unsafe_allow_html=True)

            # --- Top trades ---
            st.markdown('<div class="section-header">‚ö†Ô∏è Top Problem Trades</div>', unsafe_allow_html=True)
            if len(metrics["summary_trade"])>0:
                for idx, (_, row) in enumerate(metrics["summary_trade"].head(5).iterrows(), 1):
                    st.markdown(f'<div class="trade-item"><strong>{idx}. {row["Trade"]}</strong> ‚Äî {row["DefectCount"]} defects</div>', unsafe_allow_html=True)

            # --- Downloads ---
            st.markdown('<div class="section-header">üì• Download Reports</div>', unsafe_allow_html=True)
            mel_tz = pytz.timezone("Australia/Melbourne")
            ts = datetime.now(mel_tz).strftime("%Y%m%d_%H%M%S")
            base = f'{metrics["building_name"].replace(" ","_")}_Inspection_Report_{ts}'

            # Excel
            excel_buffer = generate_excel(final_df, metrics)
            if excel_buffer:
                st.download_button(
                    "üìä Download Excel Report",
                    data=excel_buffer,
                    file_name=f"{base}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            else:
                st.info("Install xlsxwriter to enable Excel output: pip install xlsxwriter")

            # Word ‚Äî INSTANT DOWNLOAD (no session state, no rerun)
            st.markdown("### üìÑ Professional Word Report")
            if WORD_REPORT_AVAILABLE:
                if st.button("üé® Generate Word Report (instant)", help="Generates and shows a download button immediately"):
                    with st.spinner("Creating Word document..."):
                        try:
                            from word_report_generator import generate_professional_word_report
                            doc = generate_professional_word_report(final_df, metrics)
                            buf = BytesIO()
                            doc.save(buf)
                            buf.seek(0)
                            word_bytes = buf.getvalue()
                            st.success("‚úÖ Word document generated!")
                            st.download_button(
                                "üì• Download Word Document",
                                data=word_bytes,
                                file_name=f"{base}_Professional.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                use_container_width=True
                            )
                            st.balloons()
                        except Exception as e:
                            st.error(f"‚ùå Error generating Word: {e}")
                            st.code(traceback.format_exc())
            else:
                st.error("‚ùå Word generator not available.")
                if WORD_IMPORT_ERROR:
                    st.markdown(f'<div class="error-card"><strong>Details:</strong> {WORD_IMPORT_ERROR}</div>', unsafe_allow_html=True)
                    st.info("Try: pip install python-docx  ‚Ä¢ Ensure word_report_generator.py is in the same folder")

        except Exception as e:
            st.error(f"‚ùå Error processing file: {e}")
            st.code(traceback.format_exc())
    else:
        st.info("Upload a CSV and ensure trade mapping is configured to generate reports.")

with tab3:
    st.markdown("## üìä Debug & Support")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown("#### üì¶ Dependencies")
        for mod, label in [("pandas","pandas"),("pytz","pytz"),("docx","python-docx")]:
            try:
                __import__(mod)
                st.markdown(f"‚úÖ {label}")
            except Exception:
                st.markdown(f"‚ùå {label}")
    with c2:
        st.markdown("#### üìÅ Files")
        for f in ["streamlit_app.py","word_report_generator.py"]:
            st.markdown(f"{'‚úÖ' if os.path.exists(f) else '‚ùå'} {f}")
    with c3:
        st.markdown("#### üé® Word Reports")
        if WORD_REPORT_AVAILABLE:
            st.success("Available")
        else:
            st.error("Not Available")
            if WORD_IMPORT_ERROR:
                st.code(WORD_IMPORT_ERROR)

# ---------- Footer ----------
st.markdown("---")
st.markdown(f"""
<div style="text-align:center; color:#666; font-size:.9em; padding:1rem;">
  <strong>Report time:</strong> {datetime.now(pytz.timezone('Australia/Melbourne')).strftime('%d/%m/%Y, %I:%M:%S %p %Z')}
</div>
""", unsafe_allow_html=True)
